Test Plan Document
==================
- [IDENTIFICATION INFORMATION](#identification-information)
  - [Product](#product)
  - [Project Description](#project-description)
  - [Testing Objectives](#testing-objectives)
  - [Features to be Tested](#features-to-be-tested)
  - [Features Not to Be Tested](#features-not-to-be-tested)
  - [User-Acceptance Testing](#user-acceptance-test)
  - [User-Acceptance Purpose](#user-acceptance-test-purpose)
  - [User-Acceptance Objectives](#user-acceptance-test-objectives)
  - [User-Acceptance Strategy](#user-acceptance-test-strategy)
  - [User-Acceptance Test Cases](#user-acceptance-test-cases)
  - [User-Acceptance Orientation Script](#user-acceptance-orientation-script)
  - [User Feedback Questions](#user-feedback-questions)
  - [Demographic Questionnaire](#demographic-questionnaire)
  
### Product

- **Product Name:** Stay On Track Web Application

### Project Description

The Stay on Track web application will allow users to 
set up recurring tasks of different intervals (ex: monthly, 6 months, yearly). 
Users can organize tasks by categories and will be able to mark  tasks with 
different levels of urgency and the ability to mark if the deadline for said 
task is flexible or concrete. The dashboard will display tasks in different 
sections: Overdue, Upcoming, and Completed. The web application will include 
different icon statuses to show visual progression of the tasks. For example, 
if maintenance is overdue, the appliance icon will change to have a 
broken appearance. 

### Testing Objectives

The test plan will be used to confirm that the web application meets the project 
requirements and is able to catch errors that a user may experience when using 
web application. 


### Features to be Tested 

- Task Creation & Deletion (Requirements 1 & 2)
- Task Organization (Requirement 3)
- Task Prioritization (Requirements 4 - 6)
- Task Display (Requirements 7 & 9)
- Task Scheduling (Requirement 10)
- Task Countdown (Requirement 11)
- Account Creation & Deletion (Requirements 20, 21, 27)
- Responsive Design (Requirement 26)
- Task Search (Requirement 22)
- Inputs and Features Descriptions (Requirement 23)

### Features Not to Be Tested
Features will not be tested as they are considered low priority and not part
of main purpose of web application.
- Color Customization (Requirement 12)
- Text Size Customization (Requirement 14)
- Settings Customization (Requirement 28)
- Email Notifications (Requirement 19)
- Task Notes (Requirement 16)
- Scheduling Assistance (Requirements 17 & 18)
- Task Completion Statistics (Requirement 25)
- Goal Tracking (Requirement 24)

USER-ACCEPTANCE TEST
--------------------

### User-Acceptance Test Purpose
The purpose of the user acceptance testing is to determine that the web 
application meets the project requirements and identify errors that users may 
experience when using the application for real-world use. Following each 
testing cycle, users will complete a survey to provide feedback on ease of use, 
visual design, and functional performance. The feedback will be used to guide 
improvements and future enhancements.

### User-Acceptance Test Objectives 
- Collect baseline feedback on ease of use, visual design, and functional 
performance.
- Refine web application based on user feedback and identified errors.
- Conduct follow-up surveys to gather comparative feedback after refinements and 
measure improvement.
- Perform final evaluation to confirm web application meets requirements and 
satisfies users based on ratings.

### User-Acceptance Test Strategy
The user acceptance testing will be performed by having users test specific 
features by following steps. The steps will be general to determine if the 
interface is intuitive. The users will be observed as they perform the test. 
User surveys will be used to receive feedback and gain measurable rating of 
specific qualities, such as ease of use. Feedback will be utilized to identify 
usability issues, errors, and areas of improvement. A/B testing will be used 
to help determine which layouts are more user-friendly.

Test participants should have the following skills, experience, and characteristics:
- No specific gender or age.
- Willingness to answer surveys.
- Able to provide follow-up testing and surveys for duration of testing.
- Normal or corrected-to-normal color vision.
- Experienced using either desktop, laptop, tablet, or mobile phone.

Compensation — There is no compensation for participants. 
### User-Acceptance Test Cases 
[Link to User-Acceptance Spreadsheet](https://docs.google.com/spreadsheets/d/11dUF_CXD5QZ_Sd4rQwZUygLuft3XUGi06R9DEXZEtvs/edit?usp=sharing)

### User-Acceptance Orientation Script
“You will be participating in iterative user acceptance testing of the Stay on 
Track web application. The web application’s purpose is to keep track of and 
set long-term recurring tasks. Your feedback will be used to confirm the web 
application meets the project requirements and provides a satisfying user 
experience. You will be testing the web application either on a desktop 
computer, laptop, or mobile phone depending on the testing scenario. After 
performing the scenario you will answer a survey, your responses will be kept 
anonymous. The survey will be used to determine numerical values that will be 
used to measure whether usability, design, and functionality improved after 
refinements are made. This iterative process ensures that your feedback 
contributes to enhancing the application.” 

### User feedback Questions:

Section 1: Ease of Use
- How would you rate the navigation of the web application?
  - 1 - Very difficult to navigate
  - 10 - Very easy to navigate

- How intuitive did you find the web application to be?
  - 1 - Not intuitive, I was confused on how the web application worked.
  - 10 - Very intuitive, I could determine how to complete tasks without 
          confusion.

Section 2: Visual design
- How would you rate the following statement? The layout of the web application 
  was very appealing.
  - 1 - Strongly disagree
  - 10 - Strongly agree

- How would you rate the following statement? The design elements enhanced 
  usability. (Fonts, colors, spacing, etc.)
  - 1 - Strongly disagree
  - 10 - Strongly agree

- How would you rate the following statement? The interface felt modern and 
  professional.
  - 1 - Strongly disagree
  - 10 - Strongly agree

Section 3: Functionality
- How would you rate the following statement? Features worked as expected 
  without errors.
  - 1 - Strongly disagree
  - 10 - Strongly agree

- How would you rate the following statement? I was able to accomplish the 
  intended tasks successfully.
  - 1 - Strongly disagree
  - 10 - Strongly agree

Section 4: User Satisfaction 
- How would you rate the following statement? I would consider using this 
  application in real-world scenarios.
  - 1 - Strongly disagree
  - 10 - Strongly agree

Section 5: Open Feedback (Optional)
- What did you like the most about this web application?
- What did you dislike the least about this web application?
- What additional features would you like this application to have?
- What improvements would you suggest?

### Demographic Questionnaire:
- Age:
- Occupation: 

- Primary Device used:
  - Phone
  - Tablet
  - Laptop
  - Desktop

- Please list which device you primarily use: (Example: IPhone X, or monitor size)

- How often do you use technology?
  - 1 - Not Often
  - 2 - Rarely 
  - 3 - Sometimes
  - 4 - Often
  - 5 - Very Often

- Have you used task management or productivity apps before or currently use them?
  - No
  - Yes

- If you answered yes to the previous question, which ones have you used or currently using?

Test Deliverables
-----------------
-   Test Plan
-   User-Acceptance Test Spreadsheet
-   Report of results from user surveys and changes that followed (Link will be added when testing begins)

Schedule
--------
2 Week Cycles:
- Week 1: User Acceptance Testing & Surveys
- Week 2: Feedback Analysis and refinement
